digraph {
	graph [size="17.55,17.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2307073014496 [label="
 ()" fillcolor=darkolivegreen1]
	2307072862816 [label=MeanBackward0]
	2307072863536 -> 2307072862816
	2307072863536 [label=AddmmBackward0]
	2307072862624 -> 2307072863536
	2307072900128 [label="base_cnn.fc2.bias
 (64)" fillcolor=lightblue]
	2307072900128 -> 2307072862624
	2307072862624 [label=AccumulateGrad]
	2307072863584 -> 2307072863536
	2307072863584 [label=MulBackward0]
	2307072861856 -> 2307072863584
	2307072861856 [label=ViewBackward0]
	2307072863104 -> 2307072861856
	2307072863104 [label=MeanBackward1]
	2307072862960 -> 2307072863104
	2307072862960 [label=NativeBatchNormBackward0]
	2307072863968 -> 2307072862960
	2307072863968 [label=MaxPool2DWithIndicesBackward0]
	2307072863680 -> 2307072863968
	2307072863680 [label=ReluBackward0]
	2307072863488 -> 2307072863680
	2307072863488 [label=ConvolutionBackward0]
	2307072863296 -> 2307072863488
	2307072863296 [label=NativeBatchNormBackward0]
	2307072862336 -> 2307072863296
	2307072862336 [label=MaxPool2DWithIndicesBackward0]
	2307072861808 -> 2307072862336
	2307072861808 [label=ReluBackward0]
	2307072862384 -> 2307072861808
	2307072862384 [label=ConvolutionBackward0]
	2307072862000 -> 2307072862384
	2307072862000 [label=MaxPool2DWithIndicesBackward0]
	2307072862096 -> 2307072862000
	2307072862096 [label=ReluBackward0]
	2306875562112 -> 2307072862096
	2306875562112 [label=ConvolutionBackward0]
	2307072861952 -> 2306875562112
	2307072861952 [label=MaxPool2DWithIndicesBackward0]
	2307072960352 -> 2307072861952
	2307072960352 [label=ReluBackward0]
	2307072960256 -> 2307072960352
	2307072960256 [label=ConvolutionBackward0]
	2307072962512 -> 2307072960256
	2307072962512 [label=ConvolutionBackward0]
	2307072962224 -> 2307072962512
	2307072962224 [label=AddBackward0]
	2307072961888 -> 2307072962224
	2307072961888 [label=ViewBackward0]
	2307072959632 -> 2307072961888
	2307072959632 [label=ConvolutionBackward0]
	2307072961648 -> 2307072959632
	2307072880448 [label="attention_layer.op.weight
 (1, 3, 1, 1)" fillcolor=lightblue]
	2307072880448 -> 2307072961648
	2307072961648 [label=AccumulateGrad]
	2307072962272 -> 2307072962512
	2307072897248 [label="attention_mask.weight
 (3, 3, 3, 3)" fillcolor=lightblue]
	2307072897248 -> 2307072962272
	2307072962272 [label=AccumulateGrad]
	2307072962368 -> 2307072962512
	2307072897328 [label="attention_mask.bias
 (3)" fillcolor=lightblue]
	2307072897328 -> 2307072962368
	2307072962368 [label=AccumulateGrad]
	2307072960448 -> 2307072960256
	2307072897488 [label="base_cnn.conv1_1.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	2307072897488 -> 2307072960448
	2307072960448 [label=AccumulateGrad]
	2307072962320 -> 2307072960256
	2307072897568 [label="base_cnn.conv1_1.bias
 (32)" fillcolor=lightblue]
	2307072897568 -> 2307072962320
	2307072962320 [label=AccumulateGrad]
	2307072961840 -> 2306875562112
	2307072898208 [label="base_cnn.conv2_1.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2307072898208 -> 2307072961840
	2307072961840 [label=AccumulateGrad]
	2307072962128 -> 2306875562112
	2307072898288 [label="base_cnn.conv2_1.bias
 (64)" fillcolor=lightblue]
	2307072898288 -> 2307072962128
	2307072962128 [label=AccumulateGrad]
	2307072861904 -> 2307072862384
	2307072898848 [label="base_cnn.conv3_1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2307072898848 -> 2307072861904
	2307072861904 [label=AccumulateGrad]
	2307072863056 -> 2307072862384
	2307072898928 [label="base_cnn.conv3_1.bias
 (128)" fillcolor=lightblue]
	2307072898928 -> 2307072863056
	2307072863056 [label=AccumulateGrad]
	2307072862672 -> 2307072863296
	2307072899008 [label="base_cnn.batch_norm_3.weight
 (128)" fillcolor=lightblue]
	2307072899008 -> 2307072862672
	2307072862672 [label=AccumulateGrad]
	2307072862768 -> 2307072863296
	2307072899088 [label="base_cnn.batch_norm_3.bias
 (128)" fillcolor=lightblue]
	2307072899088 -> 2307072862768
	2307072862768 [label=AccumulateGrad]
	2307072863344 -> 2307072863488
	2307072899488 [label="base_cnn.conv4_1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2307072899488 -> 2307072863344
	2307072863344 [label=AccumulateGrad]
	2307072863872 -> 2307072863488
	2307072899568 [label="base_cnn.conv4_1.bias
 (256)" fillcolor=lightblue]
	2307072899568 -> 2307072863872
	2307072863872 [label=AccumulateGrad]
	2307072864112 -> 2307072862960
	2307072899648 [label="base_cnn.batch_norm_4.weight
 (256)" fillcolor=lightblue]
	2307072899648 -> 2307072864112
	2307072864112 [label=AccumulateGrad]
	2307072862576 -> 2307072862960
	2307072899728 [label="base_cnn.batch_norm_4.bias
 (256)" fillcolor=lightblue]
	2307072899728 -> 2307072862576
	2307072862576 [label=AccumulateGrad]
	2307072864208 -> 2307072863536
	2307072864208 [label=TBackward0]
	2307072862720 -> 2307072864208
	2307072900048 [label="base_cnn.fc2.weight
 (64, 256)" fillcolor=lightblue]
	2307072900048 -> 2307072862720
	2307072862720 [label=AccumulateGrad]
	2307072862816 -> 2307073014496
}
